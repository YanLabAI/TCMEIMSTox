{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score as ROC\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import accuracy_score as ACC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score as BACC\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knnc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor as xgbr\n",
    "from xgboost import XGBClassifier as xgbc\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.linear_model import LinearRegression as LinearR\n",
    "\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "import MLfunction\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massData = pd.read_csv('./TCMEIMSTOXData.csv', index_col=0).iloc[:,3:].values\n",
    "print(massData.shape)\n",
    "MZ_index = np.concatenate([np.arange(12001), -np.arange(12001)])[massData.sum(axis=0)!=0]\n",
    "massData = massData[:,massData.sum(axis=0)!=0]\n",
    "print(massData.shape)\n",
    "labelTox = pd.read_csv('./TCMEIMSTOXData.csv', index_col=0).iloc[:,2].tolist()\n",
    "original_data = pd.read_csv('./TCMEIMSTOXData.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_index = original_data.index\n",
    "np.random.seed(1)\n",
    "new_index = np.where(np.array(labelTox)==1)[0].tolist()\n",
    "new_index += np.where(np.array(labelTox)==2)[0].tolist()\n",
    "new_index += np.random.choice(np.where(np.array(labelTox)==0)[0], 44, replace=False).tolist()\n",
    "np.random.seed(None)\n",
    "filtered_index = np.array(original_index)[new_index]\n",
    "x = StandardScaler().fit_transform(massData[new_index])\n",
    "# y = np.array(labelTox)[new_index].astype(np.int32)\n",
    "y = 1-(np.array(labelTox)[new_index].astype(np.int32)==0)\n",
    "y, np.array(labelTox)[new_index].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "new_index = np.where(np.array(labelTox)==1)[0].tolist()\n",
    "new_index += np.where(np.array(labelTox)==2)[0].tolist()\n",
    "new_index += np.random.choice(np.where(np.array(labelTox)==0)[0], 44, replace=False).tolist()\n",
    "np.random.seed(None)\n",
    "filtered_index = np.array(original_index)[new_index]\n",
    "x = StandardScaler().fit_transform(massData[new_index])\n",
    "y = 1 - (np.array(labelTox)[new_index].astype(np.int32) == 0)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "x_pca = pca.fit_transform(x)\n",
    "mask = np.any(np.abs(x_pca) > 40, axis=1)\n",
    "x_pca_filtered = x_pca[~mask]\n",
    "y_filtered = y[~mask]\n",
    "filtered_index_filtered = filtered_index[~mask]\n",
    "pc2_values = x_pca_filtered[:, 1]\n",
    "y_filtered_indices = np.where(y_filtered == 0)[0]\n",
    "top2_indices = y_filtered_indices[np.argsort(np.abs(pc2_values[y_filtered_indices]))[-2:]]\n",
    "x_final = np.delete(x_pca_filtered, top2_indices, axis=0)\n",
    "y_final = np.delete(y_filtered, top2_indices, axis=0)\n",
    "filtered_index_final = np.delete(filtered_index_filtered, top2_indices, axis=0)\n",
    "\n",
    "\n",
    "final_data_df = pd.DataFrame(x_final)\n",
    "final_data_df['Label'] = y_final\n",
    "final_data_df['Index'] = filtered_index_final\n",
    "\n",
    "#  CSV \n",
    "#final_data_df.to_csv('filtered_final_data.csv', index=False)\n",
    "x = StandardScaler().fit_transform(massData[filtered_index_final])\n",
    "y = y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "scores = []\n",
    "\n",
    "for i in list(range(0,1000)):\n",
    "    results = MLfunction.cross_val(rfc(random_state=i), x, y, random_seed=i, scoresFun=[BACC, ACC], cv=5)\n",
    "    scores.append(results.scores.mean()[0])\n",
    "    if results.scores.std()[1]<0.1 and results.scores.mean()[1]>0.66:\n",
    "        print(results.pred_all)\n",
    "        display(i, results.scores.mean(), results.scores.std(), '*'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parmas = {'random_state':range(300), \n",
    "          'n_estimators':range(1,200), \n",
    "          'max_depth':range(1,100), \n",
    "        #   'max_features':range(int(x.shape[1]**0.5),x.shape[1]), \n",
    "          'min_impurity_decrease':np.linspace(0,0.5,20), \n",
    "          'max_samples':list(range(1,60))+[None]\n",
    "          }\n",
    "\n",
    "parma_youhua = MLfunction.parmaOptimaze(rfc(random_state=794), [x, y], parmas, random_seed=794, cv=5, scoresFun=[BACC, ACC, F1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = MLfunction.cross_val(rfc(max_depth=9, n_estimators=110, random_state=23), x, y, random_seed=794, scoresFun=[BACC, ACC, F1], cv=5)\n",
    "print(\"Cross Validation Scores:\")\n",
    "print(results.scores)\n",
    "\n",
    "print(\"\\nAverage Scores:\")\n",
    "print(results.scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_trained = rfc(max_depth=9, n_estimators=110, random_state=23).fit(x, y)\n",
    "\n",
    "feature_importances = model_trained.feature_importances_\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "top_xxx = 50  \n",
    "\n",
    "\n",
    "top_features = MZ_index[sorted_indices][:top_xxx]\n",
    "top_importances = feature_importances[sorted_indices][:top_xxx]\n",
    "importance_df = pd.DataFrame({'Feature': top_features, 'Importance': top_importances})\n",
    "importance_df.to_csv('feature_importance.csv', index=False)\n",
    "\n",
    "plt.figure(figsize=[16, 9], dpi=300)\n",
    "plt.bar(range(top_xxx), top_importances)\n",
    "plt.xticks(range(top_xxx), top_features / 10, fontsize=20, rotation=45)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = rfc(max_depth=9, n_estimators=110, random_state=23).fit(x, y)\n",
    "importances = model_trained.feature_importances_\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.figure(figsize=[16, 9], dpi=300)\n",
    "plt.bar(range(len(importances)), importances, color='black')\n",
    "\n",
    "top_features = np.argsort(importances)[-3:]\n",
    "\n",
    "for idx in top_features:\n",
    "    plt.bar(idx, importances[idx], color='red', width=20)\n",
    "\n",
    "    plt.text(idx, importances[idx], f'{MZ_index[idx]/10:.1f}', ha='center', va='bottom', color='red', fontsize=12)\n",
    "\n",
    "plt.xticks(np.arange(0, len(importances), step=1200), labels=np.round(MZ_index[::1200]/10, 1), rotation=45, fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel('m/z', fontsize=40)\n",
    "plt.ylabel('Importances', fontsize=40)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_figure_classifier(y_kf=[], y_test=[], yLabels=None, labels=['Experiment', 'Prediction'],\n",
    "                             cmap=plt.cm.Reds, name='Confusion Matrix', path='./'):\n",
    "\n",
    "    plt.rcParams['font.family'] = \"Arial\"\n",
    "    plt.figure(figsize=[10, 10], dpi=300)\n",
    "    \n",
    "\n",
    "    os.makedirs(f'{path}/csv/', exist_ok=True)\n",
    "    os.makedirs(f'{path}/figure/', exist_ok=True)\n",
    "    \n",
    "    if len(y_kf) == 2:\n",
    "        kfTrue = y_kf[0]\n",
    "        kfPred = y_kf[1]\n",
    "        acc_train = ACC(kfTrue, kfPred)\n",
    "        bacc_train = BACC(kfTrue, kfPred)\n",
    "        f1_train = f1_score(kfTrue, kfPred, average='weighted')\n",
    "\n",
    "        trainPD = pd.DataFrame(columns=['True', 'Prediction', 'ACC', 'BACC', 'F1 Score'])\n",
    "        trainPD['True'] = y_kf[0]\n",
    "        trainPD['Prediction'] = y_kf[1]\n",
    "        trainPD.loc[0, ['ACC', 'BACC', 'F1 Score']] = [acc_train, bacc_train, f1_train]\n",
    "        trainPD.to_csv(f'{path}/csv/{name}_kf.csv', index=None)\n",
    "\n",
    "    if len(y_test) == 2:\n",
    "        testTrue = y_test[0]\n",
    "        testPred = y_test[1]\n",
    "        acc_test = ACC(testTrue, testPred)\n",
    "        bacc_test = BACC(testTrue, testPred)\n",
    "        f1_test = f1_score(testTrue, testPred, average='weighted')\n",
    "\n",
    "        testPD = pd.DataFrame(columns=['True', 'Prediction', 'ACC', 'BACC', 'F1 Score'])\n",
    "        testPD['True'] = y_test[0]\n",
    "        testPD['Prediction'] = y_test[1]\n",
    "        testPD.loc[0, ['ACC', 'BACC', 'F1 Score']] = [acc_test, bacc_test, f1_test]\n",
    "        testPD.to_csv(f'{path}/csv/{name}_test.csv', index=None)\n",
    "\n",
    "    if len(y_kf) + len(y_test) == 4:\n",
    "        trueALL = np.concatenate([y_kf[0], y_test[0]])\n",
    "        predALL = np.concatenate([y_kf[1], y_test[1]])\n",
    "\n",
    "        C = confusion_matrix(trueALL, predALL, labels=range(len(yLabels))).T\n",
    "        C_kf = confusion_matrix(y_kf[0], y_kf[1], labels=range(len(yLabels))).T\n",
    "        C_test = confusion_matrix(y_test[0], y_test[1], labels=range(len(yLabels))).T\n",
    "        plt.matshow(C, cmap=cmap, fignum=0)\n",
    "\n",
    "        for i in range(len(C)):\n",
    "            for j in range(len(C)):\n",
    "                plt.annotate(f'K-fold = {C_kf[j, i]}\\nTest = {C_test[j, i]}', xy=(i, j),\n",
    "                             horizontalalignment='center', verticalalignment='center', fontsize=30)  \n",
    "    else:\n",
    "        if len(y_kf) == 2:\n",
    "            trueALL = y_kf[0]\n",
    "            predALL = y_kf[1]\n",
    "        elif len(y_test) == 2:\n",
    "            trueALL = y_test[0]\n",
    "            predALL = y_test[1]\n",
    "        C = confusion_matrix(trueALL, predALL, labels=range(len(yLabels))).T\n",
    "        plt.matshow(C, cmap=cmap, fignum=0)\n",
    "\n",
    "        for i in range(len(C)):\n",
    "            for j in range(len(C)):\n",
    "                plt.annotate(C[j, i], xy=(i, j), horizontalalignment='center', verticalalignment='center',\n",
    "                             fontsize=30)  \n",
    "\n",
    "    plt.tick_params(labelsize=30, bottom=True, top=False, labelbottom=True, labeltop=False)\n",
    "    plt.xlabel(labels[0], fontsize=35, labelpad=10)\n",
    "    plt.ylabel(labels[1], fontsize=35)\n",
    "    plt.xticks(range(len(yLabels)), yLabels)\n",
    "    plt.yticks(range(len(yLabels)), yLabels)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    plt.savefig(f'{path}/figure/{name}.tif', dpi=800, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    if len(y_kf) + len(y_test) == 4:\n",
    "        print(\"ACC-kf = {:.3f}       ACC-test = {:.3f}\".format(acc_train, acc_test))\n",
    "        print(\"BACC-kf = {:.3f}      BACC-test = {:.3f}\".format(bacc_train, bacc_test))\n",
    "        print(\"F1 Score-kf = {:.3f}  F1 Score-test = {:.3f}\".format(f1_train, f1_test))\n",
    "    elif len(y_kf) == 2:\n",
    "        print(\"ACC-kf = {:.3f}\".format(acc_train))\n",
    "        print(\"BACC-kf = {:.3f}\".format(bacc_train))\n",
    "        print(\"F1 Score-kf = {:.3f}\".format(f1_train))\n",
    "    elif len(y_test) == 2:\n",
    "        print(\"ACC-test = {:.3f}\".format(acc_test))\n",
    "        print(\"BACC-test = {:.3f}\".format(bacc_test))\n",
    "        print(\"F1 Score-test = {:.3f}\".format(f1_test))\n",
    "\n",
    "\n",
    "result_figure_classifier(y_kf=[y, results.pred_all], yLabels=['Safe', 'Tox'], name='Confusion Matrix', path='./')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB\n",
    "\n",
    "\n",
    "parmas = {'n_estimators':range(1,200),\n",
    "          'learning_rate':np.arange(0.01,0.5,0.01),\n",
    "          'max_depth':range(1,1000), \n",
    "        #   'max_features':range(int(x.shape[1]**0.5),x.shape[1]), \n",
    "          'gamma':np.arange(0,5,0.5), \n",
    "          'reg_alpha':np.arange(0,5,0.05),\n",
    "          'reg_lambda':np.arange(0,5,0.05),\n",
    "          # 'max_samples':list(range(1,60))+[None],\n",
    "          }\n",
    "\n",
    "\n",
    "parma_youhua = MLfunction.parmaOptimaze(xgbc(use_label_encoder=False, objective=\"binary:logistic\"), [x, y], parmas, random_seed=794, cv=5, scoresFun=[BACC, ACC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in list(range(0,1000)):\n",
    "    results = MLfunction.cross_val(xgbc(random_state=i), x, y, random_seed=i, scoresFun=[BACC, ACC], cv=5)\n",
    "    scores.append(results.scores.mean()[0])\n",
    "    if results.scores.std()[1]<0.1 and results.scores.mean()[1]>0.66:\n",
    "        print(results.pred_all)\n",
    "        display(i, results.scores.mean(), results.scores.std(), '*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parmas = {'n_estimators':range(1,200),\n",
    "          'learning_rate':np.arange(0.01,0.5,0.01),\n",
    "          'max_depth':range(1,1000), \n",
    "        #   'max_features':range(int(x.shape[1]**0.5),x.shape[1]), \n",
    "          'gamma':np.arange(0,5,0.5), \n",
    "          'reg_alpha':np.arange(0,5,0.05),\n",
    "          'reg_lambda':np.arange(0,5,0.05),\n",
    "          # 'max_samples':list(range(1,60))+[None],\n",
    "          }\n",
    "\n",
    "parma_youhua = MLfunction.parmaOptimaze(xgbc(use_label_encoder=False, objective=\"binary:logistic\"), [x, y], parmas, random_seed=893, cv=5, scoresFun=[BACC, ACC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "results = MLfunction.cross_val(xgbc(gamma=0.0, max_depth=5, learning_rate=0.3, n_estimators=60, reg_lambda=4.9), x, y, random_seed=893, scoresFun=[BACC, ACC, F1], cv=5)\n",
    "results.scores, results.scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "parmas = {'algorithm':['ball_tree', 'kd_tree', 'brute'],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'n_neighbors':range(1,50),\n",
    "          'p':[1,2],\n",
    "          'leaf_size':range(1,100)\n",
    "          }\n",
    "\n",
    "parma_youhua = MLfunction.parmaOptimaze(knnc(), [x, y], parmas, random_seed=240, cv=5, scoresFun=[BACC, ACC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "knnc_model = knnc(algorithm='ball_tree', leaf_size=1, n_neighbors=39)\n",
    "results = MLfunction.cross_val(knnc_model, x, y, random_seed=240, scoresFun=[BACC, ACC, F1], cv=5)\n",
    "results.scores, results.scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 svm\n",
    "parmas = {'kernel':[\"rbf\", \"poly\", \"sigmoid\"],\n",
    "          'C':np.arange(1,50,0.05),\n",
    "          'gamma':np.linspace(0.0001,100/x.shape[1],200),\n",
    "          }\n",
    "\n",
    "parma_youhua = MLfunction.parmaOptimaze(svc(), [x, y], parmas, random_seed=100, cv=5, scoresFun=[BACC, ACC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = svc(C=1.7000000000000006, gamma=0.0004373368383844918, kernel='sigmoid',probability=True)\n",
    "results = MLfunction.cross_val(svc_model, x, y, random_seed=100, scoresFun=[BACC, ACC, F1], cv=5)\n",
    "results.scores, results.scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
